Ive used near-exclusively local llms for the last year or two in a number of configurations. When I started I didn't know anything about the language I was using but now I know enough to just be able to write on my own from having to correct them all the time. The experience was not very good until I got a better computer. Initially I was just copy/paste because I didn't trust them, but I got access to  Cursor Pro + Claude for a while so I started to model my ideal from that.

Lately I use VSCode with Continue extension running exaone3.5 or gpt-oss 20b/120b through Ollama with Chat only, no Agentic mode. I prefer to take things a bit slower, and Continue lets me swap out code easily vs write directly to files, which I do not tend to enjoy still. This setup I went to over Aider and OpenCode because it integrates really well with autocomplete in VSCode. I'm not a fan of the thinking models tbh, and OpenCode just didnt work for me locally, like as if they just used remote models intstead.