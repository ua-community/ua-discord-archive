> Naturally, it is possible to aim for the opposite as well. In 2022, machine learning expert Yannic Kilcher infamously trained a bot based on GPT-J on 4chan's /pol/ board, using 134.5 million /pol/ posts. The resulting "GPT-4chan" was a chaotic trolling machine, which used slurs, created conspiracy theories, and responded in ways typical of the people in said community. Kilcher let ten such bots post on /pol/ without restriction for two periods of 24 hours, and they managed to mimick its human users quite well.[20][21][22] It made 15,000 posts during the first period: about ten percent of the total /pol/ posts during that time.[23][24] Kathryn Cramer, a graduate student at the University of Vermont, tried GPT-4chan out with benign tweets as input text to see what it would come up with. “In the first trial, one of the responding posts was a single word, the N word. The seed for my third trial was, I think, a single sentence about climate change. Your tool responded by expanding it into a conspiracy theory about the Rothschilds and Jews being behind it.”[22] Kilcher's experiment was strongly criticized by other academics for its ethics or lack thereof.