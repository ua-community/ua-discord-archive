Tiles will support server-side LLMs through https://github.com/mozilla-ai/any-llm as the second inference backend after mlx-engine (the LM Studio inference library). This backend will ship after we set up our AT Proto DID based identity system in Jan/Feb, since it is currently blocked by the public and private crypto components required for zero-knowledge security. The system keeps the unencrypted private key and chat logs on the client side, inspired by the architecture described here: https://blog.mozilla.ai/introducing-any-llm-managed-platform-a-secure-cloud-vault-and-usage-tracking-service-for-all-your-llm-providers/

Also updated the product tagline to highlight to: "Tiles is your private AI assistant with offline memory". It's a privacy focused assistant that supports both offline and online models like Proton's Luma AI assistant, with the difference being: it saves your memory locally with help of fine tuned memory models (don't think Luma has memory support)